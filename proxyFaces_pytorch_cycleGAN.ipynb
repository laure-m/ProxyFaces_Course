{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAIpknLZyaer/N/4OLJ+SP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laure-m/ProxyFaces_Course/blob/main/proxyFaces_pytorch_cycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROXY FACES UCLA AUD SPRING TECH SEMINAR \n",
        "#CycleGAN (pytorch) Notebook\n",
        "This notebook will walkthrough all the steps for training and testing using cycleGAN. Take a look at the [repository](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) for more information"
      ],
      "metadata": {
        "id": "G7OxzFW63EZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***INITIAL SETUP***\n",
        "\n",
        "Step 01: Mount to your Google drive"
      ],
      "metadata": {
        "id": "eFaehwtz3Ojz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQGVEyav252s"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 02: Clone the Github Repository"
      ],
      "metadata": {
        "id": "RRwpfAi23WrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ],
      "metadata": {
        "id": "f1EW8Zat3ZcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 03: Setup + Install Requirements"
      ],
      "metadata": {
        "id": "FWGSNDmq4AwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ],
      "metadata": {
        "id": "YWC7Cbkt3dT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "O2o6sYh33eaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 04: Change Folder Directory"
      ],
      "metadata": {
        "id": "DxieKuRb4DK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/pytorch-CycleGAN-and-pix2pix"
      ],
      "metadata": {
        "id": "P8F9Wl7B3s5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***DATASETS***"
      ],
      "metadata": {
        "id": "CPnX28Zn3fqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Either Download this example dataset >> "
      ],
      "metadata": {
        "id": "qFrGtVh64j3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/pytorch-CycleGAN-and-pix2pix/datasets\n",
        "!git clone https://github.com/laure-m/datasets/tree/main/selfie2anime\n",
        "%cd /content/drive/MyDrive/pytorch-CycleGAN-and-pix2pix"
      ],
      "metadata": {
        "id": "0BWGivj94n29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OR upload your own (must have appropriate folder structure, naming, and size)\n",
        "\n",
        ">Create a datasets folder inside 'pytorch-CycleGAN-and-pix2pix'. Musyt be named exacly like 'datasets'\n",
        "\n",
        ">Create a folder inside datasets named the title of that training. Usually its face2something (face being what images you start with and something being what you want to transform it into). \n",
        "\n",
        ">Create subfolders testA, testB, trainA, and trainB under your dataset's folder. Put faces in trainA and testA and then the \"something\" inside trainB and testB. These images need to be 256x256 jpg."
      ],
      "metadata": {
        "id": "Gqx2el1b4P9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TRAINING***\n",
        "\n",
        "\n",
        "Step 01: Change the --dataroot and --name to your own dataset's path and model's name. \n"
      ],
      "metadata": {
        "id": "mbrozs8c3mWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataroot ./datasets/selfie2anime --name selfie2anime --model cycle_gan --display_id -1"
      ],
      "metadata": {
        "id": "QiWMdyZP3uja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 02: Once your model has trained, copy over the last checkpoint to a format that the testing model can automatically detect:"
      ],
      "metadata": {
        "id": "vvQWLSkzOE-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./checkpoints/selfie2anime/latest_net_G_A.pth ./checkpoints/selfie2anime/latest_net_G.pth "
      ],
      "metadata": {
        "id": "6j8YAVC3OI-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***TESTING***\n",
        "\n",
        "Change the --dataroot and --name to be consistent with your trained model's configuration.\n",
        "\n",
        "from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix: The option --model test is used for generating results of CycleGAN only for one side. This option will automatically set --dataset_mode single, which only loads the images from one set. On the contrary, using --model cycle_gan requires loading and generating results in both directions, which is sometimes unnecessary. \n",
        "\n",
        "The results will be saved at ./results/. Use --results_dir {directory_path_to_save_result} to specify the results directory."
      ],
      "metadata": {
        "id": "COJ_MgLS3wQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --dataroot datasets/selfie2anime/testA --name selfie2anime  --model test --no_dropout"
      ],
      "metadata": {
        "id": "A3PxIyb-31Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***VISUALIZE***"
      ],
      "metadata": {
        "id": "BPLo5Nhy32vZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize one of the results"
      ],
      "metadata": {
        "id": "d4Sg3Aii34-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = plt.imread('./results/selfie2anime/test_latest/images/female_10328_fake.png') plt.imshow(img)"
      ],
      "metadata": {
        "id": "BYP98QM2Onjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare against the same image from testA"
      ],
      "metadata": {
        "id": "ke-kqoJh36ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = plt.imread('./results/selfie2anime/test_latest/images/female_10328_real.png')\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "dB4jfBwwOtiU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}